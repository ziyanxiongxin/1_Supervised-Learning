{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   val1  val2  val3  class\n",
      "0    74    85   123      1\n",
      "1    73    84   122      1\n",
      "2    72    83   121      1\n",
      "3    70    81   119      1\n",
      "4    70    81   119      1\n",
      "Counter({0: 194198, 1: 50859})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_validate\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score,roc_auc_score,accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import io\n",
    "# from google.colab import files\n",
    "\n",
    "\n",
    "# uploaded = files.upload()\n",
    "# #extract the data\n",
    "# raw_df = pd.read_csv(io.BytesIO(uploaded['BitcoinHeistData.csv']))\n",
    "\n",
    "\n",
    "# #extract the data\n",
    "raw_df = pd.read_csv('~/ML_class_projects/a_1/Skin_NonSkin.txt', delimiter='\t')\n",
    "cleaned_df = raw_df.copy()\n",
    "\n",
    "\n",
    "cleaned_df['class']=np.array([1 if x==1 else 0 for x in cleaned_df['class']])\n",
    "print(cleaned_df.head(5))\n",
    "#summarize data distribution\n",
    "y=np.array(cleaned_df['class'])\n",
    "X=np.array(cleaned_df.iloc[:,:-1])\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32a1a01e3887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##cross validation to find out the best neighbor number using kd_tree or ball_tree###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mAUC_train_score_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mAUC_test_score_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "##cross validation to find out the best neighbor number using kd_tree or ball_tree###\n",
    "t=10\n",
    "cv = KFold(n_splits=t,shuffle=True)\n",
    "AUC_train_score_list=[]\n",
    "AUC_test_score_list=[]\n",
    "\n",
    "neighbors_num = [3,4,5,6,7]\n",
    "algorithms = ['kd_tree','ball_tree']\n",
    "# parameters=(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)[source]\n",
    "for neighbors in neighbors_num:\n",
    "    neigh = KNeighborsClassifier(n_neighbors=neighbors,weights='distance',algorithm='kd_tree')\n",
    "    scores =  cross_validate(neigh, X, y, scoring=['roc_auc'], cv=cv, n_jobs=-1,return_train_score=True)\n",
    "    AUC_train_score_list.append(sum(scores['train_roc_auc'])/t)\n",
    "    AUC_test_score_list.append(sum(scores['test_roc_auc'])/t)\n",
    "    \n",
    "\n",
    "# #generate Fig_1.5.\n",
    "fig_0, axs = plt.subplots(1, 1, figsize=(5, 5), sharey=True)\n",
    "axs.plot(neighbors_num,AUC_train_score_list,\"r^\",linestyle = \"--\", label='training data')\n",
    "axs.plot(neighbors_num,AUC_test_score_list,\"b^\",linestyle = \"--\",label='test data')\n",
    "axs.set_xlabel(\"neighbors_num\")\n",
    "axs.set_ylabel(\"AUC score\")\n",
    "axs.legend()\n",
    "fig_0.suptitle(\"Fig_2.5.0: AUC_score(kd_tree)\")\n",
    "fig_0.savefig(\"KNN_fig_2.5_tunning:AUC score.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########check if using ball_tree can get higher AP score######\n",
    "neigh = KNeighborsClassifier(n_neighbors=**********,weights='distance',algorithm='ball_tree')\n",
    "scores =  cross_validate(pipeline, X, y, scoring=['roc_auc'], cv=cv, n_jobs=-1,return_train_score=True)\n",
    "print(\"AUC_score on training set if using ball_tree to store:\",sum(scores['train_roc_auc'])/t)\n",
    "print(\"AUC_score on test set if using ball_tree to store:\",sum(scores['test_roc_auc'])/t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############Apply neighbors_num and storing methods to train the model##################\n",
    "Accuracy_train_score=[]\n",
    "Accuracy_test_score=[]\n",
    "Precision_test_score=[]\n",
    "Precision_train_score=[]\n",
    "training_time = []\n",
    "\n",
    "for k in range(4,11):\n",
    "    cv = KFold(n_splits=k,shuffle=True)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=******,weights='distance',algorithm='*****')\n",
    "    scores =  cross_validate(neigh, X, y, scoring=['accuracy','precision'], cv=cv, n_jobs=-1,return_train_score=True)\n",
    "    training_time.append(sum(scores['fit_time'])/k)\n",
    "    Accuracy_train_score.append(sum(scores['train_accuracy'])/k)\n",
    "    Accuracy_test_score.append(sum(scores['test_accuracy'])/k)\n",
    "    Precision_train_score.append(sum(scores['train_precision'])/k)\n",
    "    Precision_test_score.append(sum(scores['test_precision'])/k)\n",
    "    \n",
    "K= range(4,11)\n",
    "fig_1, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=False)\n",
    "axs[0].plot(K,training_time,\"r^\",linestyle = \"--\",label=\"traing_time:seconds\")\n",
    "axs[0].set_xlabel(\"training size k\")\n",
    "axs[0].set_ylabel(\"training time\")\n",
    "axs[1].plot(K,Accuracy_train_score,\"r^\",linestyle = \"--\",label='training data')\n",
    "axs[1].plot(K,Accuracy_test_score,\"b^\",linestyle = \"--\",label='test data')\n",
    "axs[1].set_xlabel(\"training size k\")\n",
    "axs[1].set_ylabel(\"accuracy_score\")\n",
    "axs[2].plot(K,Precision_train_score,\"r^\",linestyle = \"--\",label='training data')\n",
    "axs[2].plot(K,Precision_test_score,\"b^\",linestyle = \"--\",label='test data')\n",
    "axs[2].set_xlabel(\"training size k\")\n",
    "axs[2].set_ylabel(\"precision_score\")\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[2].legend()\n",
    "fig_1.suptitle(\"Fig_2.5.1: recall score(KNN)\")\n",
    "fig_1.savefig(\"NN_fig_2.5_trainnig:learning curves.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################prediction results, generate the data in table2.5.0#########\n",
    "cv = KFold(n_splits=****,shuffle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=******, random_state=123)\n",
    "neigh = KNeighborsClassifier(n_neighbors=******,weights='distance',algorithm='*****')\n",
    "scores =  cross_validate(neigh, X, y, scoring=['accuracy','precision'], cv=cv, n_jobs=-1,return_train_score=True)\n",
    "print(\"The precision scores on training set and test set are\",sum(scores['train_precision'])/4,sum(scores['test_precision'])/4)\n",
    "print(\"The accuracy scores on training set and test set are\",sum(scores['train_accuracy'])/4,sum(scores['test_accuracy'])/4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
